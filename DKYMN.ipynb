{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DKYMN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r-PX6ao2BYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "class AssismentData():\n",
        "    def __init__(self):\n",
        "        self.data = pd.read_csv(\"/content/drive/My Drive/DKT/2015_100_skill_builders_main_problems.csv\")\n",
        "\n",
        "        self.data.dropna()\n",
        "\n",
        "        self.data[\"user_id\"], _ = pd.factorize(self.data[\"user_id\"])\n",
        "        self.data[\"sequence_id\"], _ = pd.factorize(self.data[\"sequence_id\"])\n",
        "        self.data[\"skills\"] = self.data.apply(lambda x: x.sequence_id * 2 if x.correct == 0.0 else x.sequence_id * 2 + 1, axis=1)\n",
        "\n",
        "        self.data = self.data.drop(columns=\"log_id\", axis=1)\n",
        "\n",
        "        self.data = self.data.groupby(\"user_id\").filter(lambda q: len(q) > 1).copy()\n",
        "\n",
        "        self.seq = self.data.groupby('user_id').apply(\n",
        "            lambda r: (\n",
        "                r[\"sequence_id\"].values,\n",
        "                r['skills'].values,\n",
        "                r['correct'].values\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def datasetReturn(self, shuffle=None, batch_size=32, val_data=None):\n",
        "\n",
        "        dataset = tf.data.Dataset.from_generator(lambda: self.seq, output_types=(tf.int32, tf.int32, tf.int32))\n",
        "\n",
        "        if shuffle:\n",
        "            dataset = dataset.shuffle(buffer_size=shuffle)\n",
        "\n",
        "        MASK_VALUE = -1\n",
        "        dataset = dataset.padded_batch(\n",
        "            batch_size=32,\n",
        "            padding_values=( MASK_VALUE,MASK_VALUE, MASK_VALUE),\n",
        "            padded_shapes=( [None], [None], [None]),\n",
        "            drop_remainder=True\n",
        "        )\n",
        "        i = 0\n",
        "        for l in dataset.as_numpy_iterator():\n",
        "            i += 1\n",
        "\n",
        "        test_size = int(np.ceil(i * 0.2))\n",
        "        train_size = i - test_size\n",
        "        val_size = int(np.ceil(i * 0.2))\n",
        "\n",
        "        test_data = dataset.take(test_size)\n",
        "        dataset = dataset.skip(test_size)\n",
        "\n",
        "        val_data = dataset.take(val_size)\n",
        "        dataset = dataset.skip(val_size)\n",
        "\n",
        "        return dataset, test_data, val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PtXsNbBGxbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ass = AssismentData()\n",
        "train_data,test_data,val_data = ass.datasetReturn()\n",
        "val_log = 'log/val'\n",
        "train_loss_log = 'log/train'\n",
        "summary_writer = tf.summary.create_file_writer(val_log)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6sM4qFdGymF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "total_skills_correctness = 200\n",
        "total_skills = 100\n",
        "embedding_size = 100\n",
        "batchsize = 32\n",
        "M = 50\n",
        "class DKVMNcell(tf.keras.layers.AbstractRNNCell):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.units = units\n",
        "        super(DKVMNcell, self).__init__(**kwargs)\n",
        "        self.Mv = self.add_weight(shape=(M, embedding_size),\n",
        "                                  initializer='random_normal',\n",
        "                                  trainable=True)\n",
        "        self.Mv = tf.expand_dims(self.Mv,axis=0)\n",
        "    @property\n",
        "    def state_size(self):\n",
        "        return self.units\n",
        "\n",
        "    def call(self, w_attention, erase_signal_mul, add_signal_mul, states):\n",
        "        \"\"\"\n",
        "        :param w_attention: 这个应该是concept矩阵计算后的注意力权重\n",
        "        :param erase_signal: erase标志\n",
        "        :param add_signal: add标志\n",
        "        :param states: Mk矩阵\n",
        "        :return: r，Mv\n",
        "        \"\"\"\n",
        "        # 读\n",
        "        # print(w_attention.shape)(32,50) state (32,50,100)\n",
        "        r = tf.matmul(tf.expand_dims(w_attention,axis=1),states)\n",
        "        \n",
        "        # print(r.shape)(1,32,100)\n",
        "        r = r[:,0,:]\n",
        "        \n",
        "        # 写\n",
        "        states = states * erase_signal_mul + add_signal_mul\n",
        "       \n",
        "        return r, states\n",
        "\n",
        "\n",
        "class DKVMN(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(DKVMN, self).__init__()\n",
        "        # 掩码层\n",
        "        self.mask = tf.keras.layers.Masking(mask_value=-1)\n",
        "        # 题目嵌入\n",
        "        self.exercise_embedding = tf.keras.layers.Embedding(total_skills, embedding_size)\n",
        "        # 题目对错嵌入\n",
        "        self.exercise_correctness_embedding = tf.keras.layers.Embedding(total_skills_correctness, embedding_size)\n",
        "\n",
        "        self.cell = DKVMNcell(10)\n",
        "\n",
        "        self.Mk = self.add_weight(shape=(M, embedding_size),\n",
        "                                  initializer='random_normal',\n",
        "                                  trainable=True)\n",
        "\n",
        "        self.erase = tf.keras.layers.Dense(embedding_size)\n",
        "        self.add = tf.keras.layers.Dense(embedding_size, activation=\"tanh\")\n",
        "        self.r = tf.keras.layers.Dense(embedding_size, activation=\"tanh\")\n",
        "        self.p = tf.keras.layers.Dense(2,activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, skillid, skill_correctness,correctness):\n",
        "        shape = skillid.shape\n",
        "        skill_correctness = tf.expand_dims(skill_correctness, axis=-1)\n",
        "        skillid = tf.expand_dims(skillid, axis=-1)\n",
        "        # 掩码\n",
        "        skillid = self.mask(skillid)\n",
        "        skill_correctness = self.mask(skill_correctness)\n",
        "        # 映射\n",
        "        #skill_correctness_embedding = self.exercise_correctness_embedding(skill_correctness)\n",
        "        #print(skill_correctness_embedding)\n",
        "        skill_embedding = self.exercise_embedding(skillid)\n",
        "        skill_correctness_embedding = self.exercise_correctness_embedding(tf.cast(skill_correctness/2,tf.int32))\n",
        "        skill_correctness_embedding = tf.squeeze(skill_correctness_embedding, axis=2)\n",
        "        tensorlist = tf.TensorArray(dtype=tf.float32,size=0,dynamic_size=True)\n",
        "        tensorlist_batch = tf.TensorArray(dtype=tf.float32,size=0,dynamic_size=True)\n",
        "        for k in range(skill_correctness_embedding.shape[0]):\n",
        "          tensorlist = tf.TensorArray(tf.float32,size=0,dynamic_size=True)\n",
        "          for i in range(skill_correctness_embedding.shape[1]):\n",
        "            w=tensorlist.write(i,tf.cond(correctness[k,i],lambda:tf.zeros_like(skill_correctness_embedding[k,i]),lambda:tf.ones_like(skill_correctness_embedding[k,i])))\n",
        "            w.mark_used()\n",
        "          w=tensorlist_batch.write(k,tensorlist.stack())\n",
        "          w.mark_used()\n",
        "        skill_correctness_embedding = tf.concat([skill_correctness_embedding,tensorlist_batch.stack()],axis=-1)\n",
        "        \n",
        "        skill_embedding = tf.squeeze(skill_embedding, axis=2)\n",
        "        #skill_correctness_embedding = tf.squeeze(skill_correctness_embedding, axis=2)\n",
        "        # 产生 注意力权重\n",
        "        w_attention = tf.matmul(skill_embedding, tf.expand_dims(tf.transpose(self.Mk), axis=0))\n",
        "        w_attention = tf.nn.softmax(w_attention)\n",
        "\n",
        "        #  遗忘 和 更新 Mv的过程\n",
        "        erase_signal = self.erase(skill_correctness_embedding)\n",
        "        add_signal = self.add(skill_correctness_embedding)\n",
        "\n",
        "        erase_signal_mul = 1 - tf.expand_dims(w_attention, axis=-1) * tf.expand_dims(erase_signal, axis=2)\n",
        "        add_signal_mul = tf.expand_dims(w_attention, axis=-1) * tf.expand_dims(add_signal, axis=2)\n",
        "        # 遗忘和更新Mv\n",
        "        states = self.cell.Mv\n",
        "        for i in range(batchsize)[1:]:\n",
        "          states = tf.concat([states,self.cell.Mv],axis=0)\n",
        "    \n",
        "        cell_out_list = tf.TensorArray(size=0,dynamic_size=True,dtype=tf.float32)\n",
        "\n",
        "        for i in range(shape[1]):\n",
        "            r,states = self.cell(w_attention[:,i],erase_signal_mul[:,i],add_signal_mul[:,i],states)\n",
        "            w = cell_out_list.write(i,tf.expand_dims(r,axis=1))\n",
        "            w.mark_used()\n",
        "        f = cell_out_list.read(0)\n",
        "        for i in range(shape[1])[1:]:\n",
        "            f = tf.concat([f,cell_out_list.read(i)],axis=1)\n",
        "        \n",
        "        r = tf.concat([f,skill_embedding], axis=-1)\n",
        "        loss = tf.nn.softmax(self.p(self.r(r)))\n",
        "        return loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMISTOLKFmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test_one_step(skillid,skill_correctness,correctness):\n",
        "    probility = dkvmn(skillid, skill_correctness,correctness)\n",
        "\n",
        "    mask = 1 - tf.cast(tf.equal(correctness, -1), tf.int32)\n",
        "\n",
        "    mask = tf.squeeze(mask)\n",
        "    # mask掉\n",
        "    probility = tf.boolean_mask(probility, mask)\n",
        "    label = tf.boolean_mask(correctness, mask)\n",
        "\n",
        "    label = tf.one_hot(label, depth=2)\n",
        "\n",
        "    #probility = tf.concat([tf.zeros_like(probility), probility], axis=1)\n",
        "   \n",
        "    vauc.update_state(label,probility)\n",
        "\n",
        "def train_one_step(skillid,skill_correctness,correctness):\n",
        "    with tf.GradientTape() as tape:\n",
        "        probility = dkvmn(skillid,skill_correctness,correctness)\n",
        "        mask = 1 - tf.cast(tf.equal(correctness,-1),tf.int32)\n",
        "        mask = tf.squeeze(mask)\n",
        "        # mask 掉\n",
        "        probility = tf.boolean_mask(probility,mask)\n",
        "        label = tf.boolean_mask(correctness,mask)\n",
        "        \n",
        "        label = tf.one_hot(label, depth=2)\n",
        "        # 求bc\n",
        "        bc.update_state(label,probility)\n",
        "\n",
        "        loss = tf.losses.categorical_crossentropy(label,probility)\n",
        "       \n",
        "        #probility = tf.concat([tf.zeros_like(probility), probility], axis=1)\n",
        "        # 求 auc\n",
        "        # print(dkvmn.Mk)\n",
        "        # print(dkvmn.cell.Mv)\n",
        "        auc.update_state(label,probility)\n",
        "        \n",
        "        gradients = tape.gradient(loss, dkvmn.trainable_variables)\n",
        "        # 反向传播，自动微分计算\n",
        "        optimizer.apply_gradients(zip(gradients, dkvmn.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llj2Gnc_Joel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dkvmn = DKVMN()\n",
        "bc = tf.metrics.CategoricalCrossentropy()\n",
        "auc = tf.metrics.AUC()\n",
        "vauc = tf.metrics.AUC()\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNJGTP9XJpvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "737b3b2e-4cb3-442b-ca59-f568e442ae76"
      },
      "source": [
        "for epoch in range(5):\n",
        "    train_data = train_data.shuffle(32)\n",
        "    auc.reset_states()\n",
        "    vauc.reset_states()\n",
        "    bc.reset_states()\n",
        "    for  s, v, l in train_data.as_numpy_iterator():\n",
        "        train_one_step(s, v, l)\n",
        "\n",
        "    for s, v, l in val_data.as_numpy_iterator():\n",
        "        test_one_step(s, v, l)\n",
        "    print(dkvmn.cell.Mv)\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('train_auc', auc.result(), step=epoch)\n",
        "        tf.summary.scalar('val_auc', vauc.result(), step=epoch)\n",
        "\n",
        "    print(bc.result(), auc.result(), vauc.result())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.0501091  -0.00686803  0.01138464 ... -0.03902313 -0.00610312\n",
            "    0.02252177]\n",
            "  [ 0.03213963  0.05132752  0.01032587 ...  0.06699969  0.05205045\n",
            "   -0.0160228 ]\n",
            "  [-0.11225867  0.03490091  0.01659493 ...  0.0085859  -0.07784661\n",
            "   -0.01775018]\n",
            "  ...\n",
            "  [ 0.05060253  0.04744339 -0.01064355 ...  0.02177147 -0.01593327\n",
            "   -0.03493347]\n",
            "  [-0.08958747  0.09277599 -0.01870047 ... -0.08668229 -0.08171516\n",
            "   -0.00507337]\n",
            "  [-0.0221012  -0.00024011 -0.07169972 ... -0.03059022 -0.09510239\n",
            "    0.01010598]]], shape=(1, 50, 100), dtype=float32)\n",
            "tf.Tensor(0.6044991, shape=(), dtype=float32) tf.Tensor(0.7389469, shape=(), dtype=float32) tf.Tensor(0.75183535, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-0.0501091  -0.00686803  0.01138464 ... -0.03902313 -0.00610312\n",
            "    0.02252177]\n",
            "  [ 0.03213963  0.05132752  0.01032587 ...  0.06699969  0.05205045\n",
            "   -0.0160228 ]\n",
            "  [-0.11225867  0.03490091  0.01659493 ...  0.0085859  -0.07784661\n",
            "   -0.01775018]\n",
            "  ...\n",
            "  [ 0.05060253  0.04744339 -0.01064355 ...  0.02177147 -0.01593327\n",
            "   -0.03493347]\n",
            "  [-0.08958747  0.09277599 -0.01870047 ... -0.08668229 -0.08171516\n",
            "   -0.00507337]\n",
            "  [-0.0221012  -0.00024011 -0.07169972 ... -0.03059022 -0.09510239\n",
            "    0.01010598]]], shape=(1, 50, 100), dtype=float32)\n",
            "tf.Tensor(0.5828626, shape=(), dtype=float32) tf.Tensor(0.7739383, shape=(), dtype=float32) tf.Tensor(0.76222515, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-0.0501091  -0.00686803  0.01138464 ... -0.03902313 -0.00610312\n",
            "    0.02252177]\n",
            "  [ 0.03213963  0.05132752  0.01032587 ...  0.06699969  0.05205045\n",
            "   -0.0160228 ]\n",
            "  [-0.11225867  0.03490091  0.01659493 ...  0.0085859  -0.07784661\n",
            "   -0.01775018]\n",
            "  ...\n",
            "  [ 0.05060253  0.04744339 -0.01064355 ...  0.02177147 -0.01593327\n",
            "   -0.03493347]\n",
            "  [-0.08958747  0.09277599 -0.01870047 ... -0.08668229 -0.08171516\n",
            "   -0.00507337]\n",
            "  [-0.0221012  -0.00024011 -0.07169972 ... -0.03059022 -0.09510239\n",
            "    0.01010598]]], shape=(1, 50, 100), dtype=float32)\n",
            "tf.Tensor(0.5786171, shape=(), dtype=float32) tf.Tensor(0.77855027, shape=(), dtype=float32) tf.Tensor(0.7645862, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-0.0501091  -0.00686803  0.01138464 ... -0.03902313 -0.00610312\n",
            "    0.02252177]\n",
            "  [ 0.03213963  0.05132752  0.01032587 ...  0.06699969  0.05205045\n",
            "   -0.0160228 ]\n",
            "  [-0.11225867  0.03490091  0.01659493 ...  0.0085859  -0.07784661\n",
            "   -0.01775018]\n",
            "  ...\n",
            "  [ 0.05060253  0.04744339 -0.01064355 ...  0.02177147 -0.01593327\n",
            "   -0.03493347]\n",
            "  [-0.08958747  0.09277599 -0.01870047 ... -0.08668229 -0.08171516\n",
            "   -0.00507337]\n",
            "  [-0.0221012  -0.00024011 -0.07169972 ... -0.03059022 -0.09510239\n",
            "    0.01010598]]], shape=(1, 50, 100), dtype=float32)\n",
            "tf.Tensor(0.5759482, shape=(), dtype=float32) tf.Tensor(0.78083616, shape=(), dtype=float32) tf.Tensor(0.7603403, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[-0.0501091  -0.00686803  0.01138464 ... -0.03902313 -0.00610312\n",
            "    0.02252177]\n",
            "  [ 0.03213963  0.05132752  0.01032587 ...  0.06699969  0.05205045\n",
            "   -0.0160228 ]\n",
            "  [-0.11225867  0.03490091  0.01659493 ...  0.0085859  -0.07784661\n",
            "   -0.01775018]\n",
            "  ...\n",
            "  [ 0.05060253  0.04744339 -0.01064355 ...  0.02177147 -0.01593327\n",
            "   -0.03493347]\n",
            "  [-0.08958747  0.09277599 -0.01870047 ... -0.08668229 -0.08171516\n",
            "   -0.00507337]\n",
            "  [-0.0221012  -0.00024011 -0.07169972 ... -0.03059022 -0.09510239\n",
            "    0.01010598]]], shape=(1, 50, 100), dtype=float32)\n",
            "tf.Tensor(0.574886, shape=(), dtype=float32) tf.Tensor(0.78187454, shape=(), dtype=float32) tf.Tensor(0.76611847, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOmWNlI__wb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2922a80f-c48a-4f88-e585-c74fd0025917"
      },
      "source": [
        "vauc.reset_states()\n",
        "for s, v, l in test_data.as_numpy_iterator():\n",
        "    test_one_step(s, v, l)\n",
        "print(vauc.result())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.7753244, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}